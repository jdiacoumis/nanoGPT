{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e9a8ea81-be01-4e40-bb4d-611453e8038d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/nanoGPT'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c2386c5-869e-4d5f-bd69-70fa8f308d84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff08f0d2c10>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel? # was 64\n",
    "block_size = 256 # what is the maximum context length for predictions? # was 256\n",
    "embd_dim = 10  # dimensionality of the embeddings (was equal to vocab_size)\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "74de575f-4756-41c3-8493-e05657589b91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/nanoGPT'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c859eb09-855b-47aa-a612-39ecf81a3410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/shakespeare_char/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38a15f94-269f-48d4-8dd5-8a615edd28a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "378bda90-59d4-418b-9666-b608d1b9fe82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb96019a-8b5a-4b3f-919b-780f2d81ff0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44624105-69e7-41bc-8a13-4f456672eeec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9663aff5-18de-4db4-aa57-574533571b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[decode(i.tolist()) for i in xb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e327e7-02da-477e-a6e6-841982f85da2",
   "metadata": {},
   "source": [
    "# Bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4fbecbb4-6342-4912-b52c-cb2373bb761f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C) \n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)            # the cross_entropy function expects (B, C, T) i.e. C second\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            # within this function logits starts with (B,T,C) because it hasn't passed through the if-else block in forward\n",
    "            # testing with logits, loss = m(xb,yb) won't work as logits will have dim (B*T, C) due to the if-else block \n",
    "            # need to test this with logits, loss = m(xb,None) to get dim (B, T, C)\n",
    "            logits, loss = self.forward(idx)    \n",
    "            # focus only on the last time step  \n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)  dim=-1 needs to be explicitly included so that softmax can guess the dimension (C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e4d92b05-7260-48ed-a75c-5948ba6a5a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# logits, loss = m(xb,None)\n",
    "# logits.shape\n",
    "# logit_step2 = logits[:, -1, :]\n",
    "# probs = F.softmax(logit_step2, dim=-1)\n",
    "# idx_next = torch.multinomial(probs, num_samples=10) # (B, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2553da3f-660d-4630-a56b-26a2eef29beb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DYCz$bMkRZk\n",
      "gc'wb,ZT,O-zsScbtK\n",
      "ga!POz'TBFzou3:BaSGBO-3DSMBk?YLhaUhX:LVXJtDINNuwqhPM$v.t?V;ddX3rFHaAeNFw3yMwmRWfnjDsZaYzyzoINmX\n",
      "Y\n",
      "w&$\n",
      "MtofViyzvB!!&V!Ox;FdilK!,ue3:ivYeY?YBkciK;laP;HmlcdE&GDEcSXHBLqWkn-\n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4d0036fc-ea10-4a3b-8587-03e02278860d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "82b39ab1-2227-46c9-aeda-2e16821b1ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    #model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    #model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c37127cd-d507-44a3-9175-a6a67b3ca62f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 2.4548, val loss 2.4835\n",
      "step 500: train loss 2.4554, val loss 2.4836\n",
      "step 1000: train loss 2.4534, val loss 2.4829\n",
      "step 1500: train loss 2.4537, val loss 2.4829\n",
      "step 2000: train loss 2.4534, val loss 2.4823\n",
      "step 2500: train loss 2.4538, val loss 2.4841\n",
      "step 3000: train loss 2.4531, val loss 2.4824\n",
      "step 3500: train loss 2.4546, val loss 2.4840\n",
      "step 4000: train loss 2.4523, val loss 2.4835\n",
      "step 4500: train loss 2.4539, val loss 2.4838\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "063bac8c-07e1-4a16-bea4-d3173c932a39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Th fepyotssthecas l.\n",
      "TAn.\n",
      "Mourethal wave.\n",
      "se ed Pe bene ovetour?\n",
      "Cassce oros cok hedin tie s inds he te fe f tas ny, ct Clo gscest hes,\n",
      "A: du he n, soxcone.\n",
      "\n",
      "Anthatakes aghercobun ws m k s withoumas F\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(context, max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4a69a263-2f21-4831-bc35-fdd07a17a653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384, 65])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape # (B*T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "585fb36d-2fed-4c5d-945f-eab34f2de91f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape # (B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "acd5d5a8-8431-43ab-8ace-51475106116b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B, T, C = batch_size, block_size, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99326b4f-7922-405e-8eb1-4a8a70118c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xb_view = xb.view(B*T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d030ee76-15a5-4d3d-94a0-ef96d3eb3789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mask'd; for thy reve\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(xb_view[:20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3bafe006-8bcb-4a49-8d1c-dc7a321a22c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ask'd; for thy reven\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(yb[0][:20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "567f6de4-63f4-4f34-a58b-b04314963d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probs = F.softmax(logits[:20], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bab4e1f4-267d-4c37-b6b5-5fd1133f6b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_tensor = probs[7] \n",
    "test_tensor = test_tensor.cpu().detach().numpy()\n",
    "test_tensor = np.round(test_tensor,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e05af7cb-97ac-424a-80d7-2f3a49b9433f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob_dist = { ch:test_tensor[i] for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "de0cf488-0c40-4c3b-9f7b-8c82a99151d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 1e-04,\n",
       " ' ': 0.0002,\n",
       " '!': 0.0,\n",
       " '$': 1e-04,\n",
       " '&': 1e-04,\n",
       " \"'\": 0.0036,\n",
       " ',': 0.0,\n",
       " '-': 0.0,\n",
       " '.': 0.0,\n",
       " '3': 0.0,\n",
       " ':': 0.0,\n",
       " ';': 0.0,\n",
       " '?': 0.0,\n",
       " 'A': 0.0025,\n",
       " 'B': 0.0028,\n",
       " 'C': 0.0043,\n",
       " 'D': 0.0011,\n",
       " 'E': 0.0036,\n",
       " 'F': 0.0012,\n",
       " 'G': 0.0031,\n",
       " 'H': 0.0029,\n",
       " 'I': 0.0237,\n",
       " 'J': 0.0009,\n",
       " 'K': 0.0009,\n",
       " 'L': 0.0029,\n",
       " 'M': 0.0036,\n",
       " 'N': 0.0008,\n",
       " 'O': 0.0028,\n",
       " 'P': 0.0018,\n",
       " 'Q': 1e-04,\n",
       " 'R': 0.0044,\n",
       " 'S': 0.0025,\n",
       " 'T': 0.0024,\n",
       " 'U': 1e-04,\n",
       " 'V': 0.0024,\n",
       " 'W': 0.0027,\n",
       " 'X': 0.0002,\n",
       " 'Y': 0.002,\n",
       " 'Z': 0.0,\n",
       " 'a': 0.0785,\n",
       " 'b': 0.0498,\n",
       " 'c': 0.0315,\n",
       " 'd': 0.0327,\n",
       " 'e': 0.0133,\n",
       " 'f': 0.0384,\n",
       " 'g': 0.0207,\n",
       " 'h': 0.0705,\n",
       " 'i': 0.0422,\n",
       " 'j': 0.0023,\n",
       " 'k': 0.0093,\n",
       " 'l': 0.0309,\n",
       " 'm': 0.0626,\n",
       " 'n': 0.0305,\n",
       " 'o': 0.044,\n",
       " 'p': 0.0268,\n",
       " 'q': 0.0024,\n",
       " 'r': 0.014,\n",
       " 's': 0.0715,\n",
       " 't': 0.1405,\n",
       " 'u': 0.0111,\n",
       " 'v': 0.0053,\n",
       " 'w': 0.0619,\n",
       " 'x': 0.0,\n",
       " 'y': 0.0296,\n",
       " 'z': 1e-04}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3c9f2-06e3-44f9-820b-efbccb6c3e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
