{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a8ea81-be01-4e40-bb4d-611453e8038d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/nanoGPT'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2386c5-869e-4d5f-bd69-70fa8f308d84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4aad79abf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel? # was 64\n",
    "block_size = 256 # what is the maximum context length for predictions? # was 256\n",
    "embd_dim = 10  # dimensionality of the embeddings (was equal to vocab_size)\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32    # was 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74de575f-4756-41c3-8493-e05657589b91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/nanoGPT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c859eb09-855b-47aa-a612-39ecf81a3410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('data/shakespeare_char/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a15f94-269f-48d4-8dd5-8a615edd28a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378bda90-59d4-418b-9666-b608d1b9fe82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb96019a-8b5a-4b3f-919b-780f2d81ff0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44624105-69e7-41bc-8a13-4f456672eeec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9663aff5-18de-4db4-aa57-574533571b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[decode(i.tolist()) for i in xb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e327e7-02da-477e-a6e6-841982f85da2",
   "metadata": {},
   "source": [
    "# Bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fbecbb4-6342-4912-b52c-cb2373bb761f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        B, T = idx.shape\n",
    "        \n",
    "        # encode the positions of the tokens\n",
    "        T_pos = torch.arange(T, device=device)    # if T=8, T_pos = [0,1,2,3,4,5,6,7,8] etc.. also needs to be explicitly put on the device since T is an int\n",
    "        \n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)  - here C has dimension of n_embd\n",
    "        pos_emb = self.position_embedding_table(T_pos) # (T, C)\n",
    "        combined_emb = tok_emb + pos_emb    # (B, T, C) -  broadcasting works here as it gets right aligned, pos_emb gets a B dimension of 1 and it gets broadcasted across B\n",
    "        logits = self.lm_head(combined_emb) # (B,T,C_vocab_size) \n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)            # the cross_entropy function expects (B, C, T) i.e. C second\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        # NOTE: max_new_tokens needs to be less than T_pos otherwise T_pos will spill (it will try to assign a position embedding to a position that doesn't exist)\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            # within this function logits starts with (B,T,C) because it hasn't passed through the if-else block in forward\n",
    "            # testing with logits, loss = m(xb,yb) won't work as logits will have dim (B*T, C) due to the if-else block \n",
    "            # need to test this with logits, loss = m(xb,None) to get dim (B, T, C)\n",
    "            logits, loss = self.forward(idx)  \n",
    "            # focus only on the last time step  \n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)  dim=-1 needs to be explicitly included so that softmax can guess the dimension (C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c532616-54e1-4ebf-81b1-a5aea6c5cf58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#logits, loss = m.forward(xb,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cd39e3a-4bd2-45fe-a29c-9a3bfe0811dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# B, T = xb.shape\n",
    "# T_pos = torch.arange(T, device=device)\n",
    "# token_embedding_table = nn.Embedding(vocab_size, n_embd).to(device)\n",
    "# position_embedding_table = nn.Embedding(block_size, n_embd).to(device)\n",
    "# lm_head = nn.Linear(n_embd, vocab_size).to(device)\n",
    "\n",
    "# T_pos = torch.arange(T, device=device)    # if T=8, T_pos = [0,1,2,3,4,5,6,7,8] etc.. also needs to be explicitly put on the device since T is an int\n",
    "        \n",
    "# # idx and targets are both (B,T) tensor of integers\n",
    "# tok_emb = token_embedding_table(xb) # (B,T,C)  - here C has dimension of n_embd\n",
    "# pos_emb = position_embedding_table(T_pos) # (T, C)\n",
    "        \n",
    "# combined_emb = tok_emb + pos_emb    # (B, T, C) -  broadcasting works here as it gets right aligned, pos_emb gets a B dimension of 1 and it gets broadcasted across B\n",
    "        \n",
    "# logits = lm_head(combined_emb) # (B,T,C_vocab_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d92b05-7260-48ed-a75c-5948ba6a5a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # testing\n",
    "\n",
    "# # logits, loss = m(xb,None)\n",
    "# # logits.shape\n",
    "# logit_step2 = logits[:, -1, :]\n",
    "# probs = F.softmax(logit_step2, dim=-1)\n",
    "# idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "# idx = torch.cat((idx, idx_next), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2553da3f-660d-4630-a56b-26a2eef29beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "# generate from the model\n",
    "# context = torch.randint(1, 10, (1,1), device=device)\n",
    "# context\n",
    "#print(decode(m.generate(context, max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6c18528-a083-4df2-b0a3-cb749e47cff4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "logits is nan:\n",
      "tensor(False, device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([[[ 0.6258,  0.0255,  0.9545,  0.0643, -0.5024, -0.2026, -1.5671,\n",
      "          -1.0980,  0.2360, -0.2398, -0.9211,  1.5433, -0.3676, -0.7483,\n",
      "          -0.1006,  0.7307, -2.0371,  0.4931,  1.4870,  0.5910, -0.0476,\n",
      "          -1.0996, -1.7524, -1.0971,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "           0.1662,  1.2055,  0.1883, -2.1600]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "1\n",
      "logits is nan:\n",
      "tensor(False, device='cuda:0')\n",
      "tensor([0, 1], device='cuda:0')\n",
      "tensor([[[ 0.6258,  0.0255,  0.9545,  0.0643, -0.5024, -0.2026, -1.5671,\n",
      "          -1.0980,  0.2360, -0.2398, -0.9211,  1.5433, -0.3676, -0.7483,\n",
      "          -0.1006,  0.7307, -2.0371,  0.4931,  1.4870,  0.5910, -0.0476,\n",
      "          -1.0996, -1.7524, -1.0971,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "           0.1662,  1.2055,  0.1883, -2.1600],\n",
      "         [-1.0045, -1.0104, -1.0886,  1.3292, -0.9731, -0.0360, -1.5376,\n",
      "           1.9860,  0.9682,  1.6030, -0.0726, -0.4725,  0.0429, -1.5395,\n",
      "          -0.8523, -0.0596, -1.2529,  0.6750,  1.5664, -0.9238,  0.8256,\n",
      "           1.6749, -1.2630, -0.3902, -0.1277,  0.0910,  0.5422, -0.6110,\n",
      "           0.8704, -0.7082, -2.4607,  0.7230]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "2\n",
      "logits is nan:\n",
      "tensor(False, device='cuda:0')\n",
      "tensor([0, 1, 2], device='cuda:0')\n",
      "tensor([[[ 0.6258,  0.0255,  0.9545,  0.0643, -0.5024, -0.2026, -1.5671,\n",
      "          -1.0980,  0.2360, -0.2398, -0.9211,  1.5433, -0.3676, -0.7483,\n",
      "          -0.1006,  0.7307, -2.0371,  0.4931,  1.4870,  0.5910, -0.0476,\n",
      "          -1.0996, -1.7524, -1.0971,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "           0.1662,  1.2055,  0.1883, -2.1600],\n",
      "         [-1.0045, -1.0104, -1.0886,  1.3292, -0.9731, -0.0360, -1.5376,\n",
      "           1.9860,  0.9682,  1.6030, -0.0726, -0.4725,  0.0429, -1.5395,\n",
      "          -0.8523, -0.0596, -1.2529,  0.6750,  1.5664, -0.9238,  0.8256,\n",
      "           1.6749, -1.2630, -0.3902, -0.1277,  0.0910,  0.5422, -0.6110,\n",
      "           0.8704, -0.7082, -2.4607,  0.7230],\n",
      "         [-0.0478,  0.1224, -1.9634,  0.7606,  0.1928,  1.9770, -0.1755,\n",
      "          -0.4586, -0.1114, -0.0188,  0.0890, -0.6228,  0.5204,  0.4960,\n",
      "          -1.3020, -0.3713,  0.9507,  0.7443,  0.3612, -0.5346, -0.7973,\n",
      "          -0.8183, -0.0749,  1.7255,  1.0849, -1.1393,  0.0502, -1.1192,\n",
      "           0.3063, -0.6403,  0.7813,  0.7029]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "3\n",
      "logits is nan:\n",
      "tensor(False, device='cuda:0')\n",
      "tensor([0, 1, 2, 3], device='cuda:0')\n",
      "tensor([[[ 0.6258,  0.0255,  0.9545,  0.0643, -0.5024, -0.2026, -1.5671,\n",
      "          -1.0980,  0.2360, -0.2398, -0.9211,  1.5433, -0.3676, -0.7483,\n",
      "          -0.1006,  0.7307, -2.0371,  0.4931,  1.4870,  0.5910, -0.0476,\n",
      "          -1.0996, -1.7524, -1.0971,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "           0.1662,  1.2055,  0.1883, -2.1600],\n",
      "         [-1.0045, -1.0104, -1.0886,  1.3292, -0.9731, -0.0360, -1.5376,\n",
      "           1.9860,  0.9682,  1.6030, -0.0726, -0.4725,  0.0429, -1.5395,\n",
      "          -0.8523, -0.0596, -1.2529,  0.6750,  1.5664, -0.9238,  0.8256,\n",
      "           1.6749, -1.2630, -0.3902, -0.1277,  0.0910,  0.5422, -0.6110,\n",
      "           0.8704, -0.7082, -2.4607,  0.7230],\n",
      "         [-0.0478,  0.1224, -1.9634,  0.7606,  0.1928,  1.9770, -0.1755,\n",
      "          -0.4586, -0.1114, -0.0188,  0.0890, -0.6228,  0.5204,  0.4960,\n",
      "          -1.3020, -0.3713,  0.9507,  0.7443,  0.3612, -0.5346, -0.7973,\n",
      "          -0.8183, -0.0749,  1.7255,  1.0849, -1.1393,  0.0502, -1.1192,\n",
      "           0.3063, -0.6403,  0.7813,  0.7029],\n",
      "         [ 1.2984,  0.5551, -0.4653, -0.5519,  0.1770,  1.1940,  0.7686,\n",
      "           1.8164,  0.4831,  0.3505, -0.5744,  1.2531,  0.5864,  0.9114,\n",
      "           0.8951, -0.7524,  1.6730, -0.0424, -0.1176,  1.0546, -1.0835,\n",
      "           0.3048,  0.6164, -1.0682,  1.7872,  0.0895, -0.3748, -0.4781,\n",
      "          -0.4766, -0.3051, -0.2166, -0.7161]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "4\n",
      "logits is nan:\n",
      "tensor(False, device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([[[ 0.6258,  0.0255,  0.9545,  0.0643, -0.5024, -0.2026, -1.5671,\n",
      "          -1.0980,  0.2360, -0.2398, -0.9211,  1.5433, -0.3676, -0.7483,\n",
      "          -0.1006,  0.7307, -2.0371,  0.4931,  1.4870,  0.5910, -0.0476,\n",
      "          -1.0996, -1.7524, -1.0971,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "           0.1662,  1.2055,  0.1883, -2.1600],\n",
      "         [-1.0045, -1.0104, -1.0886,  1.3292, -0.9731, -0.0360, -1.5376,\n",
      "           1.9860,  0.9682,  1.6030, -0.0726, -0.4725,  0.0429, -1.5395,\n",
      "          -0.8523, -0.0596, -1.2529,  0.6750,  1.5664, -0.9238,  0.8256,\n",
      "           1.6749, -1.2630, -0.3902, -0.1277,  0.0910,  0.5422, -0.6110,\n",
      "           0.8704, -0.7082, -2.4607,  0.7230],\n",
      "         [-0.0478,  0.1224, -1.9634,  0.7606,  0.1928,  1.9770, -0.1755,\n",
      "          -0.4586, -0.1114, -0.0188,  0.0890, -0.6228,  0.5204,  0.4960,\n",
      "          -1.3020, -0.3713,  0.9507,  0.7443,  0.3612, -0.5346, -0.7973,\n",
      "          -0.8183, -0.0749,  1.7255,  1.0849, -1.1393,  0.0502, -1.1192,\n",
      "           0.3063, -0.6403,  0.7813,  0.7029],\n",
      "         [ 1.2984,  0.5551, -0.4653, -0.5519,  0.1770,  1.1940,  0.7686,\n",
      "           1.8164,  0.4831,  0.3505, -0.5744,  1.2531,  0.5864,  0.9114,\n",
      "           0.8951, -0.7524,  1.6730, -0.0424, -0.1176,  1.0546, -1.0835,\n",
      "           0.3048,  0.6164, -1.0682,  1.7872,  0.0895, -0.3748, -0.4781,\n",
      "          -0.4766, -0.3051, -0.2166, -0.7161],\n",
      "         [-2.0660,  1.0575, -1.0572,  0.9911,  2.2576,  0.3077,  0.1520,\n",
      "          -0.8397,  1.6685,  0.5976, -1.8736,  1.2910,  1.1071, -0.3694,\n",
      "           0.1930, -0.3420, -0.8461,  0.5015, -0.9656, -0.7255,  0.8796,\n",
      "           0.2168, -2.8932, -1.9850,  1.4424,  0.4341, -0.4292,  0.3666,\n",
      "           0.6744,  1.0747, -0.6815,  0.2885]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "5\n",
      "logits is nan:\n",
      "tensor(False, device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 4, 5], device='cuda:0')\n",
      "tensor([[[ 0.6258,  0.0255,  0.9545,  0.0643, -0.5024, -0.2026, -1.5671,\n",
      "          -1.0980,  0.2360, -0.2398, -0.9211,  1.5433, -0.3676, -0.7483,\n",
      "          -0.1006,  0.7307, -2.0371,  0.4931,  1.4870,  0.5910, -0.0476,\n",
      "          -1.0996, -1.7524, -1.0971,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "           0.1662,  1.2055,  0.1883, -2.1600],\n",
      "         [-1.0045, -1.0104, -1.0886,  1.3292, -0.9731, -0.0360, -1.5376,\n",
      "           1.9860,  0.9682,  1.6030, -0.0726, -0.4725,  0.0429, -1.5395,\n",
      "          -0.8523, -0.0596, -1.2529,  0.6750,  1.5664, -0.9238,  0.8256,\n",
      "           1.6749, -1.2630, -0.3902, -0.1277,  0.0910,  0.5422, -0.6110,\n",
      "           0.8704, -0.7082, -2.4607,  0.7230],\n",
      "         [-0.0478,  0.1224, -1.9634,  0.7606,  0.1928,  1.9770, -0.1755,\n",
      "          -0.4586, -0.1114, -0.0188,  0.0890, -0.6228,  0.5204,  0.4960,\n",
      "          -1.3020, -0.3713,  0.9507,  0.7443,  0.3612, -0.5346, -0.7973,\n",
      "          -0.8183, -0.0749,  1.7255,  1.0849, -1.1393,  0.0502, -1.1192,\n",
      "           0.3063, -0.6403,  0.7813,  0.7029],\n",
      "         [ 1.2984,  0.5551, -0.4653, -0.5519,  0.1770,  1.1940,  0.7686,\n",
      "           1.8164,  0.4831,  0.3505, -0.5744,  1.2531,  0.5864,  0.9114,\n",
      "           0.8951, -0.7524,  1.6730, -0.0424, -0.1176,  1.0546, -1.0835,\n",
      "           0.3048,  0.6164, -1.0682,  1.7872,  0.0895, -0.3748, -0.4781,\n",
      "          -0.4766, -0.3051, -0.2166, -0.7161],\n",
      "         [-2.0660,  1.0575, -1.0572,  0.9911,  2.2576,  0.3077,  0.1520,\n",
      "          -0.8397,  1.6685,  0.5976, -1.8736,  1.2910,  1.1071, -0.3694,\n",
      "           0.1930, -0.3420, -0.8461,  0.5015, -0.9656, -0.7255,  0.8796,\n",
      "           0.2168, -2.8932, -1.9850,  1.4424,  0.4341, -0.4292,  0.3666,\n",
      "           0.6744,  1.0747, -0.6815,  0.2885],\n",
      "         [-0.7221, -0.9141, -0.8221, -1.6358, -1.3221, -1.2953, -0.6008,\n",
      "          -1.1628, -0.2697,  0.1637,  2.1167,  0.1598,  0.2938, -0.7448,\n",
      "           1.2736,  0.6247,  0.8426,  0.6110,  0.6414, -1.5403, -0.0429,\n",
      "          -1.9318, -0.8507, -0.7448, -1.3679,  1.4416, -1.8638, -1.0699,\n",
      "           0.1224, -0.0139, -0.4864,  0.3299]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "6\n",
      "logits is nan:\n",
      "tensor(False, device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([[[ 0.6258,  0.0255,  0.9545,  0.0643, -0.5024, -0.2026, -1.5671,\n",
      "          -1.0980,  0.2360, -0.2398, -0.9211,  1.5433, -0.3676, -0.7483,\n",
      "          -0.1006,  0.7307, -2.0371,  0.4931,  1.4870,  0.5910, -0.0476,\n",
      "          -1.0996, -1.7524, -1.0971,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "           0.1662,  1.2055,  0.1883, -2.1600],\n",
      "         [-1.0045, -1.0104, -1.0886,  1.3292, -0.9731, -0.0360, -1.5376,\n",
      "           1.9860,  0.9682,  1.6030, -0.0726, -0.4725,  0.0429, -1.5395,\n",
      "          -0.8523, -0.0596, -1.2529,  0.6750,  1.5664, -0.9238,  0.8256,\n",
      "           1.6749, -1.2630, -0.3902, -0.1277,  0.0910,  0.5422, -0.6110,\n",
      "           0.8704, -0.7082, -2.4607,  0.7230],\n",
      "         [-0.0478,  0.1224, -1.9634,  0.7606,  0.1928,  1.9770, -0.1755,\n",
      "          -0.4586, -0.1114, -0.0188,  0.0890, -0.6228,  0.5204,  0.4960,\n",
      "          -1.3020, -0.3713,  0.9507,  0.7443,  0.3612, -0.5346, -0.7973,\n",
      "          -0.8183, -0.0749,  1.7255,  1.0849, -1.1393,  0.0502, -1.1192,\n",
      "           0.3063, -0.6403,  0.7813,  0.7029],\n",
      "         [ 1.2984,  0.5551, -0.4653, -0.5519,  0.1770,  1.1940,  0.7686,\n",
      "           1.8164,  0.4831,  0.3505, -0.5744,  1.2531,  0.5864,  0.9114,\n",
      "           0.8951, -0.7524,  1.6730, -0.0424, -0.1176,  1.0546, -1.0835,\n",
      "           0.3048,  0.6164, -1.0682,  1.7872,  0.0895, -0.3748, -0.4781,\n",
      "          -0.4766, -0.3051, -0.2166, -0.7161],\n",
      "         [-2.0660,  1.0575, -1.0572,  0.9911,  2.2576,  0.3077,  0.1520,\n",
      "          -0.8397,  1.6685,  0.5976, -1.8736,  1.2910,  1.1071, -0.3694,\n",
      "           0.1930, -0.3420, -0.8461,  0.5015, -0.9656, -0.7255,  0.8796,\n",
      "           0.2168, -2.8932, -1.9850,  1.4424,  0.4341, -0.4292,  0.3666,\n",
      "           0.6744,  1.0747, -0.6815,  0.2885],\n",
      "         [-0.7221, -0.9141, -0.8221, -1.6358, -1.3221, -1.2953, -0.6008,\n",
      "          -1.1628, -0.2697,  0.1637,  2.1167,  0.1598,  0.2938, -0.7448,\n",
      "           1.2736,  0.6247,  0.8426,  0.6110,  0.6414, -1.5403, -0.0429,\n",
      "          -1.9318, -0.8507, -0.7448, -1.3679,  1.4416, -1.8638, -1.0699,\n",
      "           0.1224, -0.0139, -0.4864,  0.3299],\n",
      "         [ 0.4690, -0.8725,  1.5689,  1.2495,  1.0631, -0.2301, -0.1389,\n",
      "           0.7443,  0.9712, -0.8952,  1.2868,  0.8233,  0.4344,  0.4332,\n",
      "          -0.5461,  1.2438,  0.8585, -0.6161, -0.0405, -0.0815, -1.1445,\n",
      "          -0.0623,  0.4293,  1.1996, -1.8527,  0.2914,  0.3634, -1.0550,\n",
      "          -1.3530, -0.6429,  0.9626, -0.8058]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "7\n",
      "logits is nan:\n",
      "tensor(False, device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "tensor([[[ 0.6258,  0.0255,  0.9545,  0.0643, -0.5024, -0.2026, -1.5671,\n",
      "          -1.0980,  0.2360, -0.2398, -0.9211,  1.5433, -0.3676, -0.7483,\n",
      "          -0.1006,  0.7307, -2.0371,  0.4931,  1.4870,  0.5910, -0.0476,\n",
      "          -1.0996, -1.7524, -1.0971,  0.4478, -0.8016,  1.5236,  2.5086,\n",
      "           0.1662,  1.2055,  0.1883, -2.1600],\n",
      "         [-1.0045, -1.0104, -1.0886,  1.3292, -0.9731, -0.0360, -1.5376,\n",
      "           1.9860,  0.9682,  1.6030, -0.0726, -0.4725,  0.0429, -1.5395,\n",
      "          -0.8523, -0.0596, -1.2529,  0.6750,  1.5664, -0.9238,  0.8256,\n",
      "           1.6749, -1.2630, -0.3902, -0.1277,  0.0910,  0.5422, -0.6110,\n",
      "           0.8704, -0.7082, -2.4607,  0.7230],\n",
      "         [-0.0478,  0.1224, -1.9634,  0.7606,  0.1928,  1.9770, -0.1755,\n",
      "          -0.4586, -0.1114, -0.0188,  0.0890, -0.6228,  0.5204,  0.4960,\n",
      "          -1.3020, -0.3713,  0.9507,  0.7443,  0.3612, -0.5346, -0.7973,\n",
      "          -0.8183, -0.0749,  1.7255,  1.0849, -1.1393,  0.0502, -1.1192,\n",
      "           0.3063, -0.6403,  0.7813,  0.7029],\n",
      "         [ 1.2984,  0.5551, -0.4653, -0.5519,  0.1770,  1.1940,  0.7686,\n",
      "           1.8164,  0.4831,  0.3505, -0.5744,  1.2531,  0.5864,  0.9114,\n",
      "           0.8951, -0.7524,  1.6730, -0.0424, -0.1176,  1.0546, -1.0835,\n",
      "           0.3048,  0.6164, -1.0682,  1.7872,  0.0895, -0.3748, -0.4781,\n",
      "          -0.4766, -0.3051, -0.2166, -0.7161],\n",
      "         [-2.0660,  1.0575, -1.0572,  0.9911,  2.2576,  0.3077,  0.1520,\n",
      "          -0.8397,  1.6685,  0.5976, -1.8736,  1.2910,  1.1071, -0.3694,\n",
      "           0.1930, -0.3420, -0.8461,  0.5015, -0.9656, -0.7255,  0.8796,\n",
      "           0.2168, -2.8932, -1.9850,  1.4424,  0.4341, -0.4292,  0.3666,\n",
      "           0.6744,  1.0747, -0.6815,  0.2885],\n",
      "         [-0.7221, -0.9141, -0.8221, -1.6358, -1.3221, -1.2953, -0.6008,\n",
      "          -1.1628, -0.2697,  0.1637,  2.1167,  0.1598,  0.2938, -0.7448,\n",
      "           1.2736,  0.6247,  0.8426,  0.6110,  0.6414, -1.5403, -0.0429,\n",
      "          -1.9318, -0.8507, -0.7448, -1.3679,  1.4416, -1.8638, -1.0699,\n",
      "           0.1224, -0.0139, -0.4864,  0.3299],\n",
      "         [ 0.4690, -0.8725,  1.5689,  1.2495,  1.0631, -0.2301, -0.1389,\n",
      "           0.7443,  0.9712, -0.8952,  1.2868,  0.8233,  0.4344,  0.4332,\n",
      "          -0.5461,  1.2438,  0.8585, -0.6161, -0.0405, -0.0815, -1.1445,\n",
      "          -0.0623,  0.4293,  1.1996, -1.8527,  0.2914,  0.3634, -1.0550,\n",
      "          -1.3530, -0.6429,  0.9626, -0.8058],\n",
      "         [-0.3638,  0.4825, -1.8903,  0.2387,  0.4945, -0.8841, -1.4792,\n",
      "          -0.2443, -0.8787,  1.2134,  0.7270, -0.2060, -1.6071, -0.4612,\n",
      "          -1.0280, -0.2069,  0.4760, -0.8871,  1.3709, -1.9473, -1.6613,\n",
      "           1.2640, -0.4231, -0.1834,  0.2178, -0.3297, -0.0192,  0.9225,\n",
      "           1.5641, -1.1374,  1.2083,  0.2712]]], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "8\n",
      "logits is nan:\n",
      "tensor(True, device='cuda:0')\n",
      "tensor([94207118162832,          0, 94207644661840, 94206095355024, 139956420322112,          2,\n",
      "                 8,         32,          0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1088: indexSelectSmallIndex: block: [0,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "numel: integer multiplication overflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 48\u001b[0m, in \u001b[0;36mBigramLanguageModel.generate\u001b[0;34m(self, idx, max_new_tokens)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m( torch\u001b[38;5;241m.\u001b[39misnan(logits)\u001b[38;5;241m.\u001b[39many())\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(T_pos)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtok_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# focus only on the last time step  \u001b[39;00m\n\u001b[1;32m     50\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;66;03m# becomes (B, C)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/_tensor.py:427\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    424\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/_tensor_str.py:637\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    636\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/_tensor_str.py:568\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    566\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    567\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 568\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    571\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/_tensor_str.py:328\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: numel: integer multiplication overflow"
     ]
    }
   ],
   "source": [
    "m.generate(context, max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4d0036fc-ea10-4a3b-8587-03e02278860d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "82b39ab1-2227-46c9-aeda-2e16821b1ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    #model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    #model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c37127cd-d507-44a3-9175-a6a67b3ca62f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 2.4548, val loss 2.4835\n",
      "step 500: train loss 2.4554, val loss 2.4836\n",
      "step 1000: train loss 2.4534, val loss 2.4829\n",
      "step 1500: train loss 2.4537, val loss 2.4829\n",
      "step 2000: train loss 2.4534, val loss 2.4823\n",
      "step 2500: train loss 2.4538, val loss 2.4841\n",
      "step 3000: train loss 2.4531, val loss 2.4824\n",
      "step 3500: train loss 2.4546, val loss 2.4840\n",
      "step 4000: train loss 2.4523, val loss 2.4835\n",
      "step 4500: train loss 2.4539, val loss 2.4838\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "063bac8c-07e1-4a16-bea4-d3173c932a39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Th fepyotssthecas l.\n",
      "TAn.\n",
      "Mourethal wave.\n",
      "se ed Pe bene ovetour?\n",
      "Cassce oros cok hedin tie s inds he te fe f tas ny, ct Clo gscest hes,\n",
      "A: du he n, soxcone.\n",
      "\n",
      "Anthatakes aghercobun ws m k s withoumas F\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(context, max_new_tokens=200)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4a69a263-2f21-4831-bc35-fdd07a17a653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16384, 65])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape # (B*T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "585fb36d-2fed-4c5d-945f-eab34f2de91f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape # (B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "acd5d5a8-8431-43ab-8ace-51475106116b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B, T, C = batch_size, block_size, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99326b4f-7922-405e-8eb1-4a8a70118c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xb_view = xb.view(B*T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d030ee76-15a5-4d3d-94a0-ef96d3eb3789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"mask'd; for thy reve\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(xb_view[:20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3bafe006-8bcb-4a49-8d1c-dc7a321a22c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ask'd; for thy reven\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(yb[0][:20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "567f6de4-63f4-4f34-a58b-b04314963d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probs = F.softmax(logits[:20], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bab4e1f4-267d-4c37-b6b5-5fd1133f6b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_tensor = probs[7] \n",
    "test_tensor = test_tensor.cpu().detach().numpy()\n",
    "test_tensor = np.round(test_tensor,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e05af7cb-97ac-424a-80d7-2f3a49b9433f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prob_dist = { ch:test_tensor[i] for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "de0cf488-0c40-4c3b-9f7b-8c82a99151d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 1e-04,\n",
       " ' ': 0.0002,\n",
       " '!': 0.0,\n",
       " '$': 1e-04,\n",
       " '&': 1e-04,\n",
       " \"'\": 0.0036,\n",
       " ',': 0.0,\n",
       " '-': 0.0,\n",
       " '.': 0.0,\n",
       " '3': 0.0,\n",
       " ':': 0.0,\n",
       " ';': 0.0,\n",
       " '?': 0.0,\n",
       " 'A': 0.0025,\n",
       " 'B': 0.0028,\n",
       " 'C': 0.0043,\n",
       " 'D': 0.0011,\n",
       " 'E': 0.0036,\n",
       " 'F': 0.0012,\n",
       " 'G': 0.0031,\n",
       " 'H': 0.0029,\n",
       " 'I': 0.0237,\n",
       " 'J': 0.0009,\n",
       " 'K': 0.0009,\n",
       " 'L': 0.0029,\n",
       " 'M': 0.0036,\n",
       " 'N': 0.0008,\n",
       " 'O': 0.0028,\n",
       " 'P': 0.0018,\n",
       " 'Q': 1e-04,\n",
       " 'R': 0.0044,\n",
       " 'S': 0.0025,\n",
       " 'T': 0.0024,\n",
       " 'U': 1e-04,\n",
       " 'V': 0.0024,\n",
       " 'W': 0.0027,\n",
       " 'X': 0.0002,\n",
       " 'Y': 0.002,\n",
       " 'Z': 0.0,\n",
       " 'a': 0.0785,\n",
       " 'b': 0.0498,\n",
       " 'c': 0.0315,\n",
       " 'd': 0.0327,\n",
       " 'e': 0.0133,\n",
       " 'f': 0.0384,\n",
       " 'g': 0.0207,\n",
       " 'h': 0.0705,\n",
       " 'i': 0.0422,\n",
       " 'j': 0.0023,\n",
       " 'k': 0.0093,\n",
       " 'l': 0.0309,\n",
       " 'm': 0.0626,\n",
       " 'n': 0.0305,\n",
       " 'o': 0.044,\n",
       " 'p': 0.0268,\n",
       " 'q': 0.0024,\n",
       " 'r': 0.014,\n",
       " 's': 0.0715,\n",
       " 't': 0.1405,\n",
       " 'u': 0.0111,\n",
       " 'v': 0.0053,\n",
       " 'w': 0.0619,\n",
       " 'x': 0.0,\n",
       " 'y': 0.0296,\n",
       " 'z': 1e-04}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3c9f2-06e3-44f9-820b-efbccb6c3e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
